{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed03SC1Jm9Yy"
      },
      "source": [
        "# Problemas\n",
        "\n",
        "Como vimos acima, há muitos passos na criação e definição de uma nova rede neural.\n",
        "A grande parte desses ajustes dependem diretamente do problemas.\n",
        "\n",
        "Abaixo, listamos alguns problemas. Todos os problemas e datasets usados vem do [Center for Machine Learning and Intelligent Systems](http://archive.ics.uci.edu/ml/datasets.php).\n",
        "\n",
        "\n",
        "**Seu objetivo é determinar e implementar um modelo para cada problema.**\n",
        "\n",
        "Isso inclui:\n",
        "\n",
        "1. definir uma arquitetura.\n",
        "Por enquanto usando somente camadas [Lineares](https://pytorch.org/docs/stable/nn.html#linear), porém podemos variar as ativações, como [Sigmoid](https://pytorch.org/docs/stable/nn.html#sigmoid), [Tanh](https://pytorch.org/docs/stable/nn.html#tanh), [ReLU](https://pytorch.org/docs/stable/nn.html#relu), [LeakyReLU](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html), [ELU](https://pytorch.org/docs/stable/generated/torch.nn.ELU.html), [SeLU](https://pytorch.org/docs/stable/generated/torch.nn.SELU.html), [PReLU](https://pytorch.org/docs/stable/generated/torch.nn.PReLU.html), [RReLU](https://pytorch.org/docs/stable/generated/torch.nn.RReLU.html)\n",
        "2. definir uma função de custo. Algums opções que vimos previamente incluem[L1](https://pytorch.org/docs/stable/nn.html#l1loss), [L2/MSE](https://pytorch.org/docs/stable/nn.html#mseloss), [Huber/SmoothL1](https://pytorch.org/docs/stable/nn.html#smoothl1loss), [*Cross-Entropy*](https://pytorch.org/docs/stable/nn.html#crossentropyloss), [Hinge](https://pytorch.org/docs/stable/nn.html#hingeembeddingloss)), e\n",
        "3. definir um algoritmo de otimização ([SGD](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD), [RMSProp](https://pytorch.org/docs/stable/optim.html#torch.optim.RMSprop), [Adam](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam))\n",
        "\n",
        "A leitura do dado assim como a função de treinamento já estão implementados para você."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bzMRy-nFKua"
      },
      "source": [
        "# Preâmbulo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW-VATPAldgt"
      },
      "source": [
        "# imports basicos\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch import optim, nn\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fs5RRCEpFKug",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "076ca16e-5e98-4125-eb21-1a7f9534b6e2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.ion()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.ExitStack at 0x7e7cf4ea31d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNofnRSOFKul",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d92e4b8a-0000-49d8-c9c5-a4cd3d82ce36"
      },
      "source": [
        "# Test if GPU is avaliable, if not, use cpu instead\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "n = torch.cuda.device_count()\n",
        "devices_ids = list(range(n))\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funções básicas\n",
        "\n",
        "Use a função `load_array ` declarada a seguir se voce ja tem os dados armazenados em um **array** (por exemplo um array do numpy, o `np.array`). Pode acontecer de que os nossos dados vêm simplesmente de um dataset que pode ser armazennado em um array, e portanto não é necessário fazer os outros passos mais complicados como carregar os dados do disco, etc; basta que possamos recuperar esses dados em *batches* aleatórios. O resultado dessa função é um `DataLoader` do Pytorch com os dados que fornecemos de entrada, e que permite que os acessamos da seguinte forma:\n",
        "\n",
        "```python\n",
        "data_loader = load_array(X, y, batch_size=32, is_train=True)\n",
        "for x_batch, y_batch in data_loader:\n",
        "    ### ... nossa iteração de treinamento aqui.\n",
        "```\n",
        "\n",
        "Essa função recebe como parâmetro os seguintes valores:\n",
        "\n",
        "- `features`: um array que contém as features de todas as instâncias do dataset. Por exemplo, no caso do MNIST seria um array de tamanho `(60000, 28, 28, 1)` com todas as imagens do dataset de treino.\n",
        "- `labels`: um array que contém os rótulos de cada instância de dados. No caso do MNIST, seria um array de tamanho `(60000,)` em que a posição `i` contém o rótulo do dígito da posição `i` do array `features`.\n",
        "- `batch_size`: tamanho do batch desejado\n",
        "- `is_train`: um booleano que indica se o dataset que estamos criando é o conjunto de treinamento ou não (conjunto de teste). A única mudança que isso causa no `Dataloader` resultante é que se for o conjunto de treinamento ele cria batches aleatórios.\n"
      ],
      "metadata": {
        "id": "vdHX3JaM_-7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_array(features, labels, batch_size, is_train=True):\n",
        "    \"\"\"Construct a Torch data loader\"\"\"\n",
        "\n",
        "    ## transform the input arrays in a tensor in case they are not\n",
        "    if type(features) != torch.tensor:\n",
        "        features = torch.tensor(features)\n",
        "    if type(labels) != torch.tensor:\n",
        "        labels = torch.tensor(labels)\n",
        "\n",
        "    ## create a Pytorch Dataset and DataLoader with the input data\n",
        "    dataset = torch.utils.data.TensorDataset(features, labels)\n",
        "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)"
      ],
      "metadata": {
        "id": "xAN7JCEPAEU4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a função `evaluate_accuracy` para calcular a acurácia e a *loss-function* para a rede em um conjunto de dados. Note que essa função pode ser usada tanto para avaliar a rede no conjunto de teste (no caso que usamos o `DataLoader` de teste) quanto o conjunto de treinamento (se usamos o `DataLoader` de treinamento). Os parâmetros são:\n",
        "- `data_iter`: um `DataLoader` que contém os dados que queremos usar para avaliar a rede. Repare que esse parâmetro tipicamente é o ojeto que obtemos como saída da função `load_array` para montar o nosso `DataLoader`.\n",
        "- `net`: a rede que queremos avaliar\n",
        "- `loss`: a nossa *loss-function*. Pode ser um objeto de qualquer uma das funções de perda que mencionamos acima no começo do notebook.\n",
        "\n",
        "O resultado dessa função é uma tupla em que o primeiro valor é a acurácia e o segundo a função de custo calculados."
      ],
      "metadata": {
        "id": "0Qn0Sh7KBLE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função usada para calcular acurácia\n",
        "def evaluate_accuracy(data_iter, net, loss):\n",
        "    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n",
        "\n",
        "    ## valores \"acumuladores\", que guardam a soma de, respectivamente, quantas instâncias\n",
        "    ## prevemos corretamente, quantas instâncias percorremos no dataset, e o valor da loss; para\n",
        "    ## todos os batches\n",
        "    acc_sum, n, l = 0, 0, 0\n",
        "\n",
        "    ## muda a rede para o \"modo de teste\". O que isso faz é mudar o comportamento de alguns módulos da rede,\n",
        "    ## como os módulos de Dropout e BatchNorm, que funcionam de forma diferente quando estamos treinando ou\n",
        "    ## quando estamos avaliando (ou usando em produção) a rede\n",
        "    net.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for X, y in data_iter:\n",
        "          X, y = X.to(device), y.to(device)\n",
        "          y_hat = net(X)\n",
        "          l += loss(y_hat, y.long())\n",
        "\n",
        "          ## aqui estamos calculando a quantidade de previsões que temos correta para o batch atual. o resultado\n",
        "          ## do argmax é a posição de `y_hat` que possui o maior valor. Consequentemente isso resulta na classe que\n",
        "          ## a rede deu o maior score.\n",
        "          acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "\n",
        "          ##\n",
        "          n += y.size(0)\n",
        "\n",
        "    return acc_sum / n, l.item() / len(data_iter)"
      ],
      "metadata": {
        "id": "SRGaUQsEFH0g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função `train_validate` é a função que implementa nossas iterações de treinamento padrão. Ela ja faz o trabalho de percorrer o dataset inteiro para cada época, e também de tempos em tempos avaliar a rede e mostar os resultados na tela. Para isso ela faz chamadas à função `evaluate_accuracy` declarada anteriormente (entre outras coisas). Essa função tem os segugintes parâmetros:\n",
        "- `net`: a rede que queremos treinar\n",
        "- `train_iter` e `test_iter`: nossos `DataLoaders` que criamos para acessar os dados. Esses DataLoaders podem ser criados com a função `load_array` declarada acima.\n",
        "- `trainer`: é o nosso otimizador. Podemos usar aqui qualquer um dos otimizadores que escolhermos da lista citada no começo desse notebook.\n",
        "- `loss`: a loss function que escolhemos para otimizar. Pode ser qualquer um das funções de custo citadas no começo do notebook.\n",
        "- `num_epochs`: a quantidade de épocas pelas quais queremos que o treinamento ocorra.\n",
        "- `type`: o tipo de tarefa que estamos lidando. Se for um problema de regressão, usamos `type='regression'`, e se for um problema de classificação, usamos `type='classification'`. Esse parâmetro é necessário para a função, por exemplo, saber quais métricas ele vai mostrar (acurácia, ou apenas o MSE, etc.)"
      ],
      "metadata": {
        "id": "mBmoehobG-TC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oSVf8u1Oi1m"
      },
      "source": [
        "# Função usada no treinamento e validação da rede\n",
        "def train_validate(net, train_iter, test_iter, trainer, loss, num_epochs, type='regression'):\n",
        "    print('training on', device)\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "        for X, y in train_iter:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            trainer.zero_grad()\n",
        "            y_hat = net(X)\n",
        "            if type == 'regression':\n",
        "              l = loss(y_hat, y.float())\n",
        "            else:\n",
        "              l = loss(y_hat, y.long())\n",
        "            l.backward()\n",
        "            trainer.step()\n",
        "            train_l_sum += l.item()\n",
        "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n",
        "            n += y.size(0)\n",
        "        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss)\n",
        "        if type == 'regression':\n",
        "          print('epoch %d, train loss %.4f, test loss %.4f, time %.1f sec'\n",
        "                % (epoch + 1, train_l_sum / len(train_iter), test_loss, time.time() - start))\n",
        "        else:\n",
        "          print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n",
        "              'test acc %.3f, time %.1f sec'\n",
        "              % (epoch + 1, train_l_sum / len(train_iter), train_acc_sum / n, test_loss,\n",
        "                 test_acc, time.time() - start))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use a função a seguir para inicializar os pesos da rede. Ela recebe como parâmetro um módulo da rede neural, e se for uma camada linear ele inicializa os pesos e os bias dessa camada. Embora possa parecer complicado de precisar chamar essa função para todas as camadas lineares da nossa rede, o módulos do Pytorch (que incluem tanto as redes criadas com o `nn.Sequential` ou com `nn.Module`) possuem a função `net.apply()` que recebe como parâmetro uma função e aplica ela a todos os submódulos da rede. Portanto, depois de ter criado a nossa rede, podemos chamar:\n",
        "\n",
        "```python\n",
        "net.apply(weights_init)\n",
        "```\n",
        "que automaticamente todas as camadas `nn.Linear` serão inicializadas. Caso queira saber mais sobre o `.apply()`, veja o seguinte [link](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.apply)."
      ],
      "metadata": {
        "id": "ExWzvYS9JqTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para inicializar pesos da rede\n",
        "def weights_init(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        m.weight.data.normal_(0.0, 0.01) # valores iniciais são uma normal\n",
        "        m.bias.data.fill_(0)"
      ],
      "metadata": {
        "id": "mkeIXH1PJqpA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0m-qic-0Wnl"
      },
      "source": [
        "# Problema 1\n",
        "\n",
        "Neste problema, você receberá 14 *features* coletadas de pacientes e tentará predizer se eles tem algum sinal de doença cardíaca. Mais sobre esse dataset aqui: https://archive.ics.uci.edu/ml/datasets/Heart+Disease"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## aqui fazemos o download do dataset usando o `!wget`. Se estamos rodando em um servidor linux (como é o caso do Colab),\n",
        "## podemos usar comandos do linux precedidos pelo \"!\". Por exemplo podemos fazer !ls para listar os arquivos da instância do colab.\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\n",
        "\n",
        "## aqui fazemos um tratamento inicial dos dados. \"np.genfromtxt\" lê os dados de um arquivo .txt e transforma em\n",
        "## um array. Pode ser interessante abrir o arquivo para verificar como os dados chegaram. Se estiver no colab, voce\n",
        "## pode verificar o arquivo \"processed.cleveland.data\" clicando na pastinha do canto esquerdo da página. a função\n",
        "## \"np.nan_to_num\" trata valores NaN e infinitos no dataset.\n",
        "data = np.genfromtxt('processed.cleveland.data', delimiter=',', dtype=np.float32)\n",
        "data = np.nan_to_num(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "w2V7qc5FNZpC",
        "outputId": "e5456492-0682-49e8-c318-4c916a8473fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-19 12:37:41--  https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘processed.cleveland.data’\n",
            "\n",
            "processed.cleveland     [ <=>                ]  18.03K   109KB/s    in 0.2s    \n",
            "\n",
            "2025-05-19 12:37:42 (109 KB/s) - ‘processed.cleveland.data’ saved [18461]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## aqui separamos os dados entre features (X) e rótulo (y), e depois separamos em um conjunto de treinamento e teste\n",
        "print(data.shape, data[0, :])\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "print(X.shape, X[0, :])\n",
        "print(y.shape, y[0])\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pdIA4XYoNa_2",
        "outputId": "27307ecc-b0ae-4dd5-f350-388da314e1e6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(303, 14) [ 63.    1.    1.  145.  233.    1.    2.  150.    0.    2.3   3.    0.\n",
            "   6.    0. ]\n",
            "(303, 13) [ 63.    1.    1.  145.  233.    1.    2.  150.    0.    2.3   3.    0.\n",
            "   6. ]\n",
            "(303,) 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUYOPZYH0Ztc"
      },
      "source": [
        "## aqui criamos nossos DataLoaders para conseguirmos iterar nos dados\n",
        "batch_size = 64\n",
        "train_iter = load_array(train_features, train_labels, batch_size)\n",
        "test_iter = load_array(test_features, test_labels, batch_size, False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "178XNdRUpiQW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4b9c6667-e90b-4a4e-dd87-52209eec5a17"
      },
      "source": [
        "# 1) Converta labels para binário (0 ou 1)\n",
        "train_labels_bin = (train_labels > 0).astype(np.int64)\n",
        "test_labels_bin  = (test_labels  > 0).astype(np.int64)\n",
        "\n",
        "# 2) Crie novos DataLoaders usando load_array com rótulos binários\n",
        "batch_size = 64  # já estava definido acima\n",
        "train_iter = load_array(train_features, train_labels_bin, batch_size, is_train=True)\n",
        "test_iter  = load_array(test_features,  test_labels_bin,  batch_size, is_train=False)\n",
        "\n",
        "# 3) Definição da rede (MLP simples: 14 → 64 → 32 → 2)\n",
        "# Substitua “14” por train_features.shape[1], que deve ser 13\n",
        "in_dim = train_features.shape[1]  # normalmente 13\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(in_dim, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 2)\n",
        ")\n",
        "\n",
        "net.apply(weights_init)\n",
        "net.to(device)\n",
        "\n",
        "# 4) Loss e otimizador\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "trainer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# 5) Treinamento e validação\n",
        "#    (observe que aqui passamos type='classification')\n",
        "train_validate(net, train_iter, test_iter, trainer, loss_fn, num_epochs=20, type='classification')\n",
        "\n",
        "# 6) Mostre as 5 primeiras previsões no conjunto de teste\n",
        "X5 = torch.tensor(test_features[0:5], dtype=torch.float32).to(device)\n",
        "logits = net(X5)\n",
        "preds = logits.argmax(dim=1).cpu().numpy()\n",
        "print(\"Predições:\", preds)\n",
        "print(\"Verdadeiros (binário):\", test_labels_bin[0:5])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cuda\n",
            "epoch 1, train loss 0.6937, train acc 0.496, test loss 0.6925, test acc 0.475, time 0.7 sec\n",
            "epoch 2, train loss 0.6909, train acc 0.558, test loss 0.6940, test acc 0.475, time 0.0 sec\n",
            "epoch 3, train loss 0.6862, train acc 0.558, test loss 0.6954, test acc 0.475, time 0.0 sec\n",
            "epoch 4, train loss 0.6860, train acc 0.558, test loss 0.7004, test acc 0.475, time 0.0 sec\n",
            "epoch 5, train loss 0.6820, train acc 0.558, test loss 0.6948, test acc 0.475, time 0.0 sec\n",
            "epoch 6, train loss 0.6783, train acc 0.558, test loss 0.6835, test acc 0.475, time 0.0 sec\n",
            "epoch 7, train loss 0.6713, train acc 0.562, test loss 0.6771, test acc 0.492, time 0.0 sec\n",
            "epoch 8, train loss 0.6646, train acc 0.583, test loss 0.6681, test acc 0.557, time 0.0 sec\n",
            "epoch 9, train loss 0.6497, train acc 0.587, test loss 0.6586, test acc 0.607, time 0.0 sec\n",
            "epoch 10, train loss 0.6416, train acc 0.624, test loss 0.6448, test acc 0.656, time 0.0 sec\n",
            "epoch 11, train loss 0.6300, train acc 0.645, test loss 0.6345, test acc 0.656, time 0.0 sec\n",
            "epoch 12, train loss 0.6118, train acc 0.682, test loss 0.6144, test acc 0.689, time 0.0 sec\n",
            "epoch 13, train loss 0.5962, train acc 0.711, test loss 0.6059, test acc 0.689, time 0.0 sec\n",
            "epoch 14, train loss 0.5825, train acc 0.686, test loss 0.5769, test acc 0.689, time 0.0 sec\n",
            "epoch 15, train loss 0.5751, train acc 0.736, test loss 0.5578, test acc 0.689, time 0.0 sec\n",
            "epoch 16, train loss 0.5673, train acc 0.694, test loss 0.5468, test acc 0.705, time 0.0 sec\n",
            "epoch 17, train loss 0.5533, train acc 0.731, test loss 0.5259, test acc 0.721, time 0.0 sec\n",
            "epoch 18, train loss 0.5338, train acc 0.740, test loss 0.5360, test acc 0.705, time 0.0 sec\n",
            "epoch 19, train loss 0.5461, train acc 0.736, test loss 0.5049, test acc 0.738, time 0.0 sec\n",
            "epoch 20, train loss 0.5383, train acc 0.731, test loss 0.4985, test acc 0.738, time 0.0 sec\n",
            "Predições: [0 1 1 0 1]\n",
            "Verdadeiros (binário): [0 1 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDaRVNq1aMpm"
      },
      "source": [
        "# Problema 2\n",
        "\n",
        "Neste problema, você receberá 90 *features* extraídas de diversas músicas (datadas de 1922 até 2011) e deve predizer o ano de cada música. Mais sobre esse dataset aqui: https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWdBT3zhW_Y5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f5fbb342-5980-47f6-94c9-a504d2b8c3eb"
      },
      "source": [
        "# download do dataset\n",
        "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\n",
        "!unzip YearPredictionMSD.txt.zip\n",
        "data = np.genfromtxt('YearPredictionMSD.txt', delimiter=',', dtype=np.float32)\n",
        "\n",
        "print(data[0, :])\n",
        "X, y = data[:, 1:], data[:, 0]\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "batch_size = 100\n",
        "train_iter = load_array(train_features, train_labels, batch_size)\n",
        "test_iter = load_array(test_features, test_labels, batch_size, False)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-19 12:37:59--  http://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘YearPredictionMSD.txt.zip’\n",
            "\n",
            "YearPredictionMSD.t     [  <=>               ] 201.24M  8.24MB/s    in 21s     \n",
            "\n",
            "2025-05-19 12:38:21 (9.49 MB/s) - ‘YearPredictionMSD.txt.zip’ saved [211011981]\n",
            "\n",
            "Archive:  YearPredictionMSD.txt.zip\n",
            "  inflating: YearPredictionMSD.txt   \n",
            "[ 2.0010000e+03  4.9943569e+01  2.1471140e+01  7.3077499e+01\n",
            "  8.7486095e+00 -1.7406281e+01 -1.3099050e+01 -2.5012020e+01\n",
            " -1.2232570e+01  7.8308902e+00 -2.4678299e+00  3.3213601e+00\n",
            " -2.3152101e+00  1.0205560e+01  6.1110913e+02  9.5108960e+02\n",
            "  6.9811426e+02  4.0898486e+02  3.8370911e+02  3.2651511e+02\n",
            "  2.3811327e+02  2.5142413e+02  1.8717351e+02  1.0042652e+02\n",
            "  1.7919498e+02 -8.4155798e+00 -3.1787039e+02  9.5862663e+01\n",
            "  4.8102589e+01 -9.5663033e+01 -1.8062149e+01  1.9698400e+00\n",
            "  3.4424381e+01  1.1726700e+01  1.3679000e+00  7.7944398e+00\n",
            " -3.6994001e-01 -1.3367851e+02 -8.3261650e+01 -3.7297649e+01\n",
            "  7.3046669e+01 -3.7366840e+01 -3.1385300e+00 -2.4215309e+01\n",
            " -1.3230660e+01  1.5938090e+01 -1.8604780e+01  8.2154793e+01\n",
            "  2.4057980e+02 -1.0294070e+01  3.1584311e+01 -2.5381870e+01\n",
            " -3.9077201e+00  1.3292580e+01  4.1550598e+01 -7.2627201e+00\n",
            " -2.1008631e+01  1.0550848e+02  6.4298561e+01  2.6084810e+01\n",
            " -4.4591099e+01 -8.3065701e+00  7.9370599e+00 -1.0736600e+01\n",
            " -9.5447662e+01 -8.2033073e+01 -3.5591942e+01  4.6952500e+00\n",
            "  7.0956261e+01  2.8091391e+01  6.0201502e+00 -3.7137669e+01\n",
            " -4.1124500e+01 -8.4081602e+00  7.1987700e+00 -8.6017599e+00\n",
            " -5.9085698e+00 -1.2324370e+01  1.4687340e+01 -5.4321251e+01\n",
            "  4.0147861e+01  1.3016200e+01 -5.4405479e+01  5.8993671e+01\n",
            "  1.5373440e+01  1.1114399e+00 -2.3087931e+01  6.8407951e+01\n",
            " -1.8222300e+00 -2.7463480e+01  2.2632699e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoHCfAjzft_3",
        "outputId": "34a20112-c525-4560-eaae-ac84e19487b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# 1) Definição da rede (90 → 128 → 64 → 1)\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(90, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 1)\n",
        ")\n",
        "net.apply(weights_init)\n",
        "net.to(device)\n",
        "\n",
        "# 2) Loss e otimizador (MSE para regressão)\n",
        "loss_fn = nn.MSELoss()\n",
        "trainer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# 3) Treinamento e validação\n",
        "#    (note type='regression')\n",
        "train_validate(net, train_iter, test_iter, trainer, loss_fn, num_epochs=10, type='regression')\n",
        "\n",
        "# 4) Mostre as 5 primeiras previsões no conjunto de teste\n",
        "X5 = torch.tensor(test_features[0:5, :], dtype=torch.float32).to(device)\n",
        "preds = net(X5).detach().cpu().numpy().reshape(-1)\n",
        "print(\"Previsões:\", preds)\n",
        "print(\"Verdadeiros:\", test_labels[0:5])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([100])) that is different to the input size (torch.Size([100, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([81])) that is different to the input size (torch.Size([81, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, train loss 111923.4511, test loss 21915.5650, time 10.1 sec\n",
            "epoch 2, train loss 20181.5152, test loss 18164.2387, time 10.0 sec\n",
            "epoch 3, train loss 17190.5193, test loss 20780.6655, time 10.2 sec\n",
            "epoch 4, train loss 15910.3928, test loss 15040.0894, time 10.3 sec\n",
            "epoch 5, train loss 14977.2437, test loss 14438.9101, time 10.2 sec\n",
            "epoch 6, train loss 13849.7679, test loss 16514.6373, time 10.3 sec\n",
            "epoch 7, train loss 13385.4365, test loss 11951.7484, time 9.6 sec\n",
            "epoch 8, train loss 12667.7801, test loss 13426.1999, time 10.2 sec\n",
            "epoch 9, train loss 12151.1241, test loss 11337.6696, time 10.2 sec\n",
            "epoch 10, train loss 11812.7895, test loss 11021.0888, time 10.2 sec\n",
            "Previsões: [2048.9194 2099.081  2171.239  1719.4153 1912.717 ]\n",
            "Verdadeiros: [2008. 2001. 2006. 2008. 1998.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNMAyyX8jSb8",
        "outputId": "c12467d8-35f7-46db-d043-c184727b6d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# mostra o resultado predito para as 5 primeiras instâncias de teste\n",
        "y = net(torch.Tensor(test_features[0:5, :]).to(device))\n",
        "print(y, test_labels[0:5])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2048.9194],\n",
            "        [2099.0811],\n",
            "        [2171.2390],\n",
            "        [1719.4153],\n",
            "        [1912.7170]], device='cuda:0', grad_fn=<AddmmBackward0>) [2008. 2001. 2006. 2008. 1998.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd8hG7HCDUib"
      },
      "source": [
        "# Problema 3\n",
        "\n",
        "Neste problema, você receberá várias *features* (como altura média, inclinação, etc) descrevendo uma região e o modelo deve predizer qual o tipo da região (floresta, montanha, etc). Mais informações sobre esse dataset aqui: https://archive.ics.uci.edu/ml/datasets/covertype"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZcIXGqBDznB",
        "outputId": "68a38891-500d-4222-de39-005b3ce8904f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\n",
        "!gzip covtype.data.gz\n",
        "data = np.genfromtxt('covtype.data', delimiter=',', dtype=np.float32)\n",
        "\n",
        "print(data.shape, data[0, :])\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "print(X.shape, X[0, :])\n",
        "print(y.shape, y[0])\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "train_labels = train_labels - 1\n",
        "test_labels = test_labels - 1\n",
        "\n",
        "batch_size = 100\n",
        "train_iter = load_array(train_features, train_labels, batch_size)\n",
        "test_iter = load_array(test_features, test_labels, batch_size, False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-19 12:44:01--  http://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘covtype.data.gz’\n",
            "\n",
            "covtype.data.gz         [         <=>        ]  10.72M  3.99MB/s    in 2.7s    \n",
            "\n",
            "2025-05-19 12:44:04 (3.99 MB/s) - ‘covtype.data.gz’ saved [11240707]\n",
            "\n",
            "gzip: covtype.data.gz already has .gz suffix -- unchanged\n",
            "(581012, 55) [2.596e+03 5.100e+01 3.000e+00 2.580e+02 0.000e+00 5.100e+02 2.210e+02\n",
            " 2.320e+02 1.480e+02 6.279e+03 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 5.000e+00]\n",
            "(581012, 54) [2.596e+03 5.100e+01 3.000e+00 2.580e+02 0.000e+00 5.100e+02 2.210e+02\n",
            " 2.320e+02 1.480e+02 6.279e+03 1.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 1.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00\n",
            " 0.000e+00 0.000e+00 0.000e+00 0.000e+00 0.000e+00]\n",
            "(581012,) 5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O0HJVIOZZW4",
        "outputId": "3a760ede-608b-4b5f-c0a3-94e462d69b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# 1) Definição da rede (54 → 128 → 64 → 7)\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(54, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 7)\n",
        ")\n",
        "net.apply(weights_init)\n",
        "net.to(device)\n",
        "\n",
        "# 2) Loss e otimizador\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "trainer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# 3) Treinamento e validação (classificação)\n",
        "train_validate(net, train_iter, test_iter, trainer, loss_fn, num_epochs=20, type='classification')\n",
        "\n",
        "# 4) Mostre as 5 primeiras previsões no conjunto de teste\n",
        "X5 = torch.tensor(test_features[0:5, :], dtype=torch.float32).to(device)\n",
        "preds = net(X5).argmax(dim=1).cpu().numpy()\n",
        "print(\"Predições:\", preds)\n",
        "print(\"Verdadeiros:\", test_labels[0:5])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cuda\n",
            "epoch 1, train loss 0.7442, train acc 0.677, test loss 0.6518, test acc 0.717, time 11.0 sec\n",
            "epoch 2, train loss 0.6483, train acc 0.717, test loss 0.6315, test acc 0.721, time 11.2 sec\n",
            "epoch 3, train loss 0.6226, train acc 0.727, test loss 0.6023, test acc 0.736, time 11.2 sec\n",
            "epoch 4, train loss 0.6066, train acc 0.735, test loss 0.5883, test acc 0.748, time 11.2 sec\n",
            "epoch 5, train loss 0.5923, train acc 0.742, test loss 0.6189, test acc 0.731, time 11.2 sec\n",
            "epoch 6, train loss 0.5795, train acc 0.748, test loss 0.5739, test acc 0.752, time 11.1 sec\n",
            "epoch 7, train loss 0.5717, train acc 0.752, test loss 0.5512, test acc 0.760, time 11.2 sec\n",
            "epoch 8, train loss 0.5636, train acc 0.755, test loss 0.5447, test acc 0.762, time 11.1 sec\n",
            "epoch 9, train loss 0.5559, train acc 0.758, test loss 0.5699, test acc 0.753, time 11.3 sec\n",
            "epoch 10, train loss 0.5491, train acc 0.762, test loss 0.5312, test acc 0.774, time 11.3 sec\n",
            "epoch 11, train loss 0.5474, train acc 0.762, test loss 0.6123, test acc 0.726, time 11.0 sec\n",
            "epoch 12, train loss 0.5398, train acc 0.766, test loss 0.5559, test acc 0.754, time 11.1 sec\n",
            "epoch 13, train loss 0.5354, train acc 0.768, test loss 0.5404, test acc 0.767, time 11.3 sec\n",
            "epoch 14, train loss 0.5309, train acc 0.771, test loss 0.5223, test acc 0.773, time 11.4 sec\n",
            "epoch 15, train loss 0.5290, train acc 0.772, test loss 0.5254, test acc 0.772, time 11.4 sec\n",
            "epoch 16, train loss 0.5253, train acc 0.773, test loss 0.5078, test acc 0.781, time 11.2 sec\n",
            "epoch 17, train loss 0.5209, train acc 0.776, test loss 0.5378, test acc 0.774, time 11.2 sec\n",
            "epoch 18, train loss 0.5195, train acc 0.776, test loss 0.5196, test acc 0.777, time 11.1 sec\n",
            "epoch 19, train loss 0.5160, train acc 0.778, test loss 0.5040, test acc 0.788, time 11.1 sec\n",
            "epoch 20, train loss 0.5158, train acc 0.779, test loss 0.5156, test acc 0.777, time 11.3 sec\n",
            "Predições: [6 1 1 1 1]\n",
            "Verdadeiros: [0. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOAxsRz0rpZl"
      },
      "source": [
        "# Problema 4\n",
        "\n",
        "Neste problema, você receberá 11 *features* extraídas de tipos de vinhos, e terá que predizer um *score* para cada vinho. Mais sobre esse dataset aqui: https://archive.ics.uci.edu/ml/datasets/Wine+Quality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knTzA0O6rusi",
        "outputId": "25d297a2-b49f-4171-f5ba-b85e5f9a0d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# download do dataset\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\n",
        "data_red = np.genfromtxt('winequality-red.csv', delimiter=';', dtype=np.float32, skip_header=1)\n",
        "data_white = np.genfromtxt('winequality-white.csv', delimiter=';', dtype=np.float32, skip_header=1)\n",
        "data = np.concatenate((data_red, data_white), axis=0)\n",
        "data = np.nan_to_num(data)\n",
        "\n",
        "print(data[0, :])\n",
        "X, y = data[:, :-1], data[:, -1]\n",
        "print(X.shape, y.shape)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "batch_size = 100\n",
        "train_iter = load_array(train_features, train_labels, batch_size)\n",
        "test_iter = load_array(test_features, test_labels, batch_size, False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-19 12:50:54--  https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘winequality-red.csv’\n",
            "\n",
            "winequality-red.csv     [   <=>              ]  82.23K   166KB/s    in 0.5s    \n",
            "\n",
            "2025-05-19 12:50:55 (166 KB/s) - ‘winequality-red.csv’ saved [84199]\n",
            "\n",
            "--2025-05-19 12:50:55--  https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘winequality-white.csv’\n",
            "\n",
            "winequality-white.c     [   <=>              ] 258.23K   392KB/s    in 0.7s    \n",
            "\n",
            "2025-05-19 12:50:57 (392 KB/s) - ‘winequality-white.csv’ saved [264426]\n",
            "\n",
            "[ 7.4     0.7     0.      1.9     0.076  11.     34.      0.9978  3.51\n",
            "  0.56    9.4     5.    ]\n",
            "(6497, 11) (6497,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E7pwns4rx9l",
        "outputId": "be9956fd-46fb-42b7-cca6-08d8069b30ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# 1) Definição da rede (11 → 64 → 32 → 1)\n",
        "net = nn.Sequential(\n",
        "    nn.Linear(11, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 1)\n",
        ")\n",
        "net.apply(weights_init)\n",
        "net.to(device)\n",
        "\n",
        "# 2) Loss e otimizador (MSE para regressão)\n",
        "loss_fn = nn.MSELoss()\n",
        "trainer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# 3) Treinamento e validação (regressão)\n",
        "train_validate(net, train_iter, test_iter, trainer, loss_fn, num_epochs=10, type='regression')\n",
        "\n",
        "# 4) Mostre as 5 primeiras previsões no conjunto de teste\n",
        "X5 = torch.tensor(test_features[0:5, :], dtype=torch.float32).to(device)\n",
        "preds = net(X5).detach().cpu().numpy().reshape(-1)\n",
        "print(\"Previsões:\", preds)\n",
        "print(\"Verdadeiros:\", test_labels[0:5])\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training on cuda\n",
            "epoch 1, train loss 22.5988, test loss 7.4813, time 0.2 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([52])) that is different to the input size (torch.Size([52, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([45])) that is different to the input size (torch.Size([45, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2, train loss 5.3107, test loss 4.5352, time 0.2 sec\n",
            "epoch 3, train loss 3.7196, test loss 3.0502, time 0.2 sec\n",
            "epoch 4, train loss 2.1815, test loss 1.4511, time 0.2 sec\n",
            "epoch 5, train loss 1.0770, test loss 0.8801, time 0.2 sec\n",
            "epoch 6, train loss 0.8882, test loss 0.8599, time 0.2 sec\n",
            "epoch 7, train loss 0.8827, test loss 0.8802, time 0.2 sec\n",
            "epoch 8, train loss 0.8850, test loss 0.8543, time 0.2 sec\n",
            "epoch 9, train loss 0.8783, test loss 0.8533, time 0.2 sec\n",
            "epoch 10, train loss 0.8771, test loss 0.8460, time 0.2 sec\n",
            "Previsões: [6.2013845 5.8325014 6.0860577 5.686197  5.9482117]\n",
            "Verdadeiros: [8. 5. 7. 6. 6.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-At99Iqzryg8",
        "outputId": "790e2253-1076-4886-d366-7445636f9c83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# mostra o resultado predito para as 5 primeiras instâncias de teste\n",
        "y = net(torch.Tensor(test_features[0:5, :]).to(device))\n",
        "print(y, test_labels[0:5])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6.2014],\n",
            "        [5.8325],\n",
            "        [6.0861],\n",
            "        [5.6862],\n",
            "        [5.9482]], device='cuda:0', grad_fn=<AddmmBackward0>) [8. 5. 7. 6. 6.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LVIg2E-W7hVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}